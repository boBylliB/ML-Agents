{
    "name": "root",
    "gauges": {
        "DroneRacerB.Policy.Entropy.mean": {
            "value": -1.2025072574615479,
            "min": -1.202850341796875,
            "max": -0.9872806668281555,
            "count": 199
        },
        "DroneRacerB.Policy.Entropy.sum": {
            "value": -11724.4462890625,
            "min": -12478.6083984375,
            "max": -4097.21484375,
            "count": 199
        },
        "DroneRacerB.Environment.EpisodeLength.mean": {
            "value": 53.053763440860216,
            "min": 38.20229007633588,
            "max": 78.58208955223881,
            "count": 199
        },
        "DroneRacerB.Environment.EpisodeLength.sum": {
            "value": 9868.0,
            "min": 3206.0,
            "max": 11406.0,
            "count": 199
        },
        "DroneRacerB.Step.mean": {
            "value": 5799961.0,
            "min": 3819988.0,
            "max": 5799961.0,
            "count": 199
        },
        "DroneRacerB.Step.sum": {
            "value": 5799961.0,
            "min": 3819988.0,
            "max": 5799961.0,
            "count": 199
        },
        "DroneRacerB.Policy.ExtrinsicValueEstimate.mean": {
            "value": 209.23023986816406,
            "min": 209.23023986816406,
            "max": 769.4522705078125,
            "count": 199
        },
        "DroneRacerB.Policy.ExtrinsicValueEstimate.sum": {
            "value": 43938.3515625,
            "min": 43938.3515625,
            "max": 183524.6875,
            "count": 199
        },
        "DroneRacerB.Environment.CumulativeReward.mean": {
            "value": 258.7052251208912,
            "min": 162.8083453669803,
            "max": 1695.2729127106843,
            "count": 199
        },
        "DroneRacerB.Environment.CumulativeReward.sum": {
            "value": 48377.87709760666,
            "min": 42655.786486148834,
            "max": 229860.34530639648,
            "count": 199
        },
        "DroneRacerB.Policy.ExtrinsicReward.mean": {
            "value": 258.7052251208912,
            "min": 162.8083453669803,
            "max": 1695.2729127106843,
            "count": 199
        },
        "DroneRacerB.Policy.ExtrinsicReward.sum": {
            "value": 48377.87709760666,
            "min": 42655.786486148834,
            "max": 229860.34530639648,
            "count": 199
        },
        "DroneRacerB.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 199
        },
        "DroneRacerB.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 199
        },
        "DroneRacerB.Losses.PolicyLoss.mean": {
            "value": 0.015521137975156307,
            "min": 0.015521137975156307,
            "max": 0.03475964109723766,
            "count": 192
        },
        "DroneRacerB.Losses.PolicyLoss.sum": {
            "value": 0.015521137975156307,
            "min": 0.015521137975156307,
            "max": 0.03475964109723766,
            "count": 192
        },
        "DroneRacerB.Losses.ValueLoss.mean": {
            "value": 38955.283203125,
            "min": 29598.689973958335,
            "max": 85929.82265625,
            "count": 192
        },
        "DroneRacerB.Losses.ValueLoss.sum": {
            "value": 38955.283203125,
            "min": 29598.689973958335,
            "max": 85929.82265625,
            "count": 192
        },
        "DroneRacerB.Policy.LearningRate.mean": {
            "value": 0.000282621530792825,
            "min": 0.000282621530792825,
            "max": 0.00028852005382665,
            "count": 192
        },
        "DroneRacerB.Policy.LearningRate.sum": {
            "value": 0.000282621530792825,
            "min": 0.000282621530792825,
            "max": 0.00028852005382665,
            "count": 192
        },
        "DroneRacerB.Policy.Epsilon.mean": {
            "value": 0.19420717499999995,
            "min": 0.19420717499999995,
            "max": 0.1961733500000001,
            "count": 192
        },
        "DroneRacerB.Policy.Epsilon.sum": {
            "value": 0.19420717499999995,
            "min": 0.19420717499999995,
            "max": 0.1961733500000001,
            "count": 192
        },
        "DroneRacerB.Policy.Beta.mean": {
            "value": 0.0004716151575000002,
            "min": 0.0004716151575000002,
            "max": 0.00048124941499999986,
            "count": 192
        },
        "DroneRacerB.Policy.Beta.sum": {
            "value": 0.0004716151575000002,
            "min": 0.0004716151575000002,
            "max": 0.00048124941499999986,
            "count": 192
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1713809728",
        "python_version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Unity Projects\\ML-Agents\\venv_3-10\\Scripts\\mlagents-learn D:\\Unity Projects\\ML-Agents\\MLAgents\\config\\DroneRacerB.yaml --run-id DroneRacerB5 --resume --initialize-from DroneRacerB4",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu118",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1713811148"
    },
    "total": 1419.7839658000012,
    "count": 1,
    "self": 0.008944000001065433,
    "children": {
        "run_training.setup": {
            "total": 0.20503250000001572,
            "count": 1,
            "self": 0.20503250000001572
        },
        "TrainerController.start_learning": {
            "total": 1419.5699893,
            "count": 1,
            "self": 1.426706600266698,
            "children": {
                "TrainerController._reset_env": {
                    "total": 13.621658399999433,
                    "count": 1,
                    "self": 13.621658399999433
                },
                "TrainerController.advance": {
                    "total": 1404.4082919997327,
                    "count": 60046,
                    "self": 1.203518999989683,
                    "children": {
                        "env_step": {
                            "total": 767.1916329998185,
                            "count": 60046,
                            "self": 654.5947412997721,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 111.8113989001049,
                                    "count": 60048,
                                    "self": 3.5709541003125196,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 108.24044479979239,
                                            "count": 39909,
                                            "self": 108.24044479979239
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.785492799941494,
                                    "count": 60045,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1363.7869611998813,
                                            "count": 60045,
                                            "is_parallel": true,
                                            "self": 867.0206209996504,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.007414699999571894,
                                                    "count": 3,
                                                    "is_parallel": true,
                                                    "self": 0.0010426000008010305,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.006372099998770864,
                                                            "count": 6,
                                                            "is_parallel": true,
                                                            "self": 0.006372099998770864
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 496.75892550023127,
                                                    "count": 60045,
                                                    "is_parallel": true,
                                                    "self": 18.07447619987761,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 27.315904000071896,
                                                            "count": 60045,
                                                            "is_parallel": true,
                                                            "self": 27.315904000071896
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 407.8243503001195,
                                                            "count": 60045,
                                                            "is_parallel": true,
                                                            "self": 407.8243503001195
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 43.54419500016229,
                                                            "count": 60045,
                                                            "is_parallel": true,
                                                            "self": 8.24869439970098,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 35.29550060046131,
                                                                    "count": 120090,
                                                                    "is_parallel": true,
                                                                    "self": 35.29550060046131
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 636.0131399999245,
                            "count": 60045,
                            "self": 2.212812299876532,
                            "children": {
                                "process_trajectory": {
                                    "total": 279.6711119000738,
                                    "count": 60045,
                                    "self": 279.1906511000743,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.48046079999949143,
                                            "count": 4,
                                            "self": 0.48046079999949143
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 354.1292157999742,
                                    "count": 193,
                                    "self": 238.85969599991586,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 115.26951980005833,
                                            "count": 5793,
                                            "self": 115.26951980005833
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 2.1000001652282663e-05,
                    "count": 1,
                    "self": 2.1000001652282663e-05
                },
                "TrainerController._save_models": {
                    "total": 0.11331129999962286,
                    "count": 1,
                    "self": 0.004853199998251512,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.10845810000137135,
                            "count": 1,
                            "self": 0.10845810000137135
                        }
                    }
                }
            }
        }
    }
}